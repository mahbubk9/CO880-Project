\documentclass[a4paper]{report}
\begin{document}
\title{Self-Learning Agents in Stochastic Games}
\author{Mahbub khan}
\date{}
\maketitle
\pagenumbering{roman}
\chapter*{Declaration}
\tableofcontents
\listoffigures
\listoftables

\begin{abstract}
\end{abstract}
\pagenumbering{arabic}

\chapter{Introduction}
\label{ch:intro}





\chapter{Problem Description}
\label{ch:description}
This is a reference \cite{Mnih2015},





\chapter{Literature \& Tech Review}
\label{ch:review}

\section{Literature Review}

Main Papers to review \cite{Mnih2015},\cite{Mnih13},\cite{ODonoghueMKM16},\cite{LevineS18:journals/corr/abs-1805-00909},\cite{Silver14},\cite{Haaronja17},\cite{Haaronja18},\cite{Junhyuk2018}

\section{Tech Review}

\subsection{Reinforcement Learning and Markov Decision Process}

\subsection{Q-Learning}

\subsection{Policy Gradient}

\subsection{Actor-Critic Algorithms}
\subsubsection{Deep Deterministic Policy Gradient}
\subsubsection{Advantage Actor Critic}








\chapter{Methods}
\label{ch:methods}

\subsection{Maximum Entropy RL}

This is the paper I am using as theory
\cite{LevineS18:journals/corr/abs-1805-00909}



\subsection{Soft Q-Learning and Soft Actor-Critic}


\cite{Haaronja17}

This is the algorithm I want to use 
\cite{Haaronja18}








\chapter{Implementation}
\label{ch:implimentation}
\subsection{Pseudo Code: Soft Actor-Critic Algorithm}






\chapter{Results}
\label{ch:results}

\subsection{Comparison between Deep Deterministic Policy Gradient(DDPG),Advantage Actor Critic(A2C), Soft Actor Critic(SAC)}











\chapter{Summary}
\label{ch:summary}







\chapter{Overview \& Outlook}
\label{ch:Evaluation}







\bibliographystyle{abbrv}
\bibliography{thesis}
\end{document}